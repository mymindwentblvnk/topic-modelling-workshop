{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8609c1",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a36dc2",
   "metadata": {},
   "source": [
    "From someone who does not understand Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "384da00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1c7b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab23745",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffd4d2",
   "metadata": {},
   "source": [
    "#### Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "230bdb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def pickle_save(obj, path):\n",
    "     with open(path, 'wb') as out:\n",
    "        pickle.dump(obj, out, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "\n",
    "def pickle_load(path):\n",
    "     with open(path, 'rb') as obj:\n",
    "        return pickle.load(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e38b5",
   "metadata": {},
   "source": [
    "#### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14b3a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def _remove_html_tags(text):\n",
    "    cleaner = re.compile('<.*?>')\n",
    "    return re.sub(cleaner, '', text)\n",
    "\n",
    "\n",
    "def _remove_control_chars(text):\n",
    "    text = text.replace('\\n','')\n",
    "    text = text.replace('\\t','')\n",
    "    return text\n",
    "\n",
    "\n",
    "def _remove_stop_words(text):\n",
    "    stop_words = list()\n",
    "    stop_words.extend(stopwords.words('english'))\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = _remove_html_tags(text)\n",
    "    text = _remove_control_chars(text)\n",
    "    text = _remove_stop_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ce988",
   "metadata": {},
   "source": [
    "#### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86222872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_bio(artist_name: str):\n",
    "    return clean_text(artist_name + \" data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728c254",
   "metadata": {},
   "source": [
    "# Buckle Up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2e185ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_SCRATCH = True\n",
    "MODEL_PATH = 'model.pickle'\n",
    "MAPPING_PATH = 'mapping.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1adcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                      requirements.txt\r\n",
      "mapping.pickle                 topic-modelling-workshop.ipynb\r\n",
      "model.pickle                   \u001b[1m\u001b[36mvenv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls  # With ! you can run bash commands in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a6395",
   "metadata": {},
   "source": [
    "## Data Cleansing and Preparation\n",
    "\n",
    "We create so called documents that consist of the artist name and their biography in tokenized format.\n",
    "\n",
    "The mapping looks something like this\n",
    "\n",
    "```\n",
    "{\n",
    "    1: {'artist_name': '50 Cent', 'bio': ['a', 'text', 'about', '50', 'Cent'},\n",
    "    2: {'artist_name': 'Eminem', 'bio': ['a', 'text', 'about', 'Eminem'},\n",
    "    3: {'artist_name': 'Metallica', 'bio': ['a', 'text', 'about', 'Metallica'},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a9e687",
   "metadata": {},
   "source": [
    "### Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8236010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50 Cent', 'Eminem', 'Metallica', 'Obie Trice']\n"
     ]
    }
   ],
   "source": [
    "artist_names = [\n",
    "    '50 Cent',\n",
    "    'Eminem',\n",
    "    'Metallica',\n",
    "    'Obie Trice'\n",
    "]\n",
    "\n",
    "print(artist_names[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77137dae",
   "metadata": {},
   "source": [
    "### Load Artists Bios and Create Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "147da698",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FROM_SCRATCH:\n",
    "    mapping = {}\n",
    "    for doc_number, artist_name in enumerate(artist_names):\n",
    "        bio = get_artist_bio(artist_name)\n",
    "        if bio:\n",
    "            mapping[doc_number] = {\n",
    "                'artist_name': artist_name,\n",
    "                'bio': bio,\n",
    "            }\n",
    "    pickle_save(mapping, MAPPING_PATH)\n",
    "else:\n",
    "    mapping = pickle_load(MAPPING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f150364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'artist_name': '50 Cent', 'bio': ['50', 'Cent', 'data']},\n",
      " 1: {'artist_name': 'Eminem', 'bio': ['Eminem', 'data']},\n",
      " 2: {'artist_name': 'Metallica', 'bio': ['Metallica', 'data']},\n",
      " 3: {'artist_name': 'Obie Trice', 'bio': ['Obie', 'Trice', 'data']}}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd849bf",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eac257",
   "metadata": {},
   "source": [
    "#### <Machine Learning Magic World ðŸ§™â€â™‚ï¸>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `Â¯\\_(ãƒ„)_/Â¯`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d1e1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyModel:\n",
    "    dictionary: Dictionary\n",
    "    tfidf_model: TfidfModel\n",
    "    lsi_model: LsiModel\n",
    "    index: MatrixSimilarity\n",
    "    \n",
    "\n",
    "if FROM_SCRATCH:\n",
    "    dataset = [mapping[i]['bio'] for i in mapping]\n",
    "    \n",
    "    dct = Dictionary(dataset)\n",
    "\n",
    "    corpus = [dct.doc2bow(line) for line in dataset]\n",
    "    tfidf_model = TfidfModel(corpus)\n",
    "    tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "    lsi_model = LsiModel(tfidf_corpus, id2word=dct, num_topics=50, power_iters=4)\n",
    "\n",
    "    index = MatrixSimilarity(lsi_model[tfidf_corpus])\n",
    "    my_model = MyModel(dictionary=dct,\n",
    "                       tfidf_model=tfidf_model,\n",
    "                       lsi_model=lsi_model,\n",
    "                       index=index)\n",
    "    pickle_save(my_model, MODEL_PATH)\n",
    "else:\n",
    "    my_model = pickle_load(MODEL_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd508c3",
   "metadata": {},
   "source": [
    "#### </Machine Learning Magic World ðŸ§™â€â™‚ï¸>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dc9a3",
   "metadata": {},
   "source": [
    "## Query the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2cbaf",
   "metadata": {},
   "source": [
    "Create the query entity data as we did when creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8dc349a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bio = get_entity_data('Obie Trice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7fd06",
   "metadata": {},
   "source": [
    "#### <Machine Learning Magic World ðŸ§™â€â™‚ï¸>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `Â¯\\_(ãƒ„)_/Â¯`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2786a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "similar_entities = my_model.index[vec_lsi]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fbd5e",
   "metadata": {},
   "source": [
    "#### </Machine Learning Magic World ðŸ§™â€â™‚ï¸>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3241de0",
   "metadata": {},
   "source": [
    "## The Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e864b",
   "metadata": {},
   "source": [
    "We got all the doc numbers (see `mapping`) and how good they match with the queried artist (0.0 to 1.0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12a26bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: 0.0, 2: 2.9802322e-08, 3: 1.0}\n"
     ]
    }
   ],
   "source": [
    "doc_number_to_propability = dict(enumerate(similar_entities))\n",
    "\n",
    "print(doc_number_to_propability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c24c4",
   "metadata": {},
   "source": [
    "Now let's find the top 10 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "863b2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'artist_name': 'Obie Trice', 'propability': 1.0},\n",
      " {'artist_name': 'Metallica', 'propability': 2.9802322e-08},\n",
      " {'artist_name': '50 Cent', 'propability': 0.0},\n",
      " {'artist_name': 'Eminem', 'propability': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "top_n_docs = sorted(d, key=d.get, reverse=True)[:10]\n",
    "\n",
    "result = []\n",
    "for doc_number in top_n_docs:\n",
    "    result.append({\n",
    "        'propability': similar_entities[doc_number],\n",
    "        'artist_name': mapping[doc_number]['artist_name']\n",
    "    })\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760808b2",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f777aa33",
   "metadata": {},
   "source": [
    "### ðŸ¤– `I am a semi professional ML implementation AMA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e3f08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_artists(artist_name):\n",
    "    query_bio = get_entity_data(artist_name)\n",
    "    vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "    vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "    similar_entities = my_model.index[vec_lsi]\n",
    "    doc_number_to_propability = dict(enumerate(similar_entities))\n",
    "    top_n_docs = sorted(d, key=d.get, reverse=True)[:10]\n",
    "\n",
    "    result = []\n",
    "    for doc_number in top_n_docs:\n",
    "        result.append({\n",
    "            'propability': similar_entities[doc_number],\n",
    "            'artist_name': mapping[doc_number]['artist_name']\n",
    "        })\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93844d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'artist_name': 'Obie Trice', 'propability': 0.0},\n",
      " {'artist_name': 'Metallica', 'propability': 0.0},\n",
      " {'artist_name': '50 Cent', 'propability': 0.0},\n",
      " {'artist_name': 'Eminem', 'propability': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "find_similar_artists(\"Rihanna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e4079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
