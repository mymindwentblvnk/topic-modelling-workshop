{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8609c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a36dc2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From someone who does not understand Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3fc49e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Serialize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def pickle_save(obj, path):\n",
    "     with open(path, 'wb') as out:\n",
    "        pickle.dump(obj, out, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "\n",
    "def pickle_load(path):\n",
    "     with open(path, 'rb') as obj:\n",
    "        return pickle.load(obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Text Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def _remove_html_tags(text):\n",
    "    cleaner = re.compile('<.*?>')\n",
    "    return re.sub(cleaner, '', text)\n",
    "\n",
    "\n",
    "def _remove_control_chars(text):\n",
    "    text = text.replace('\\n','')\n",
    "    text = text.replace('\\t','')\n",
    "    return text\n",
    "\n",
    "\n",
    "def _remove_stop_words(text):\n",
    "    stop_words = list()\n",
    "    stop_words.extend(stopwords.words('english'))\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "    return \" \".join(list(result))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = _remove_html_tags(text)\n",
    "    text = text.lower()\n",
    "    text = _remove_control_chars(text)\n",
    "    text = _remove_stop_words(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gather Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pylast\n",
    "import settings\n",
    "\n",
    "\n",
    "client = pylast.LastFMNetwork(api_key=settings.API_KEY,\n",
    "                              api_secret=settings.API_SECRET,\n",
    "                              username=settings.USER,\n",
    "                              password_hash=pylast.md5(settings.PASSWORD))\n",
    "\n",
    "\n",
    "def get_artist_bio(artist_name: str):\n",
    "    try:\n",
    "        artist = client.get_artist(artist_name)\n",
    "        bio = artist.get_bio_content()\n",
    "\n",
    "        if bio and 'There are at least' not in bio:  # No perfect match found\n",
    "            return bio\n",
    "    except pylast.WSError:\n",
    "        print(f\"Bio for {artist_name} cannot be found.\")\n",
    "    except pylast.MalformedResponseError:\n",
    "        print(f\"Bio for {artist_name} cannot be found.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Buckle Up!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FROM_SCRATCH = True\n",
    "INPUT_DATA_PATH = 'data/data.csv'\n",
    "MODEL_PATH = 'model.pickle'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!tree -I venv # With ! you can run bash commands in Jupyter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleansing and Preparation\n",
    "\n",
    "We create so called documents that consist of the artist name and their biography in tokenized format.\n",
    "\n",
    "The mapping looks something like this\n",
    "\n",
    "```\n",
    "{\n",
    "    1: {'artist_name': '50 Cent', 'bio': ['a', 'text', 'about', '50', 'Cent'},\n",
    "    2: {'artist_name': 'Eminem', 'bio': ['a', 'text', 'about', 'Eminem'},\n",
    "    3: {'artist_name': 'Metallica', 'bio': ['a', 'text', 'about', 'Metallica'},\n",
    "    ...\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Input Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> list:\n",
    "    with open(path, 'r', newline='') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        return [row for row in csv_reader]\n",
    "\n",
    "    \n",
    "rows = load_csv(INPUT_DATA_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(rows[2727])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for doc_number, r in enumerate(rows, 1):\n",
    "    mapping[doc_number] = {\n",
    "        'artist_name': r[0], \n",
    "        'bio': clean_text(r[1])\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(mapping[2728])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <Machine Learning Magic World 🧙‍♂️>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `¯\\_(ツ)_/¯`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyModel:\n",
    "    dictionary: Dictionary\n",
    "    tfidf_model: TfidfModel\n",
    "    lsi_model: LsiModel\n",
    "    index: MatrixSimilarity\n",
    "    \n",
    "\n",
    "if FROM_SCRATCH:\n",
    "    dataset = [mapping[i]['bio'] for i in mapping]\n",
    "    \n",
    "    dct = Dictionary(dataset)\n",
    "\n",
    "    corpus = [dct.doc2bow(line) for line in dataset]\n",
    "    tfidf_model = TfidfModel(corpus)\n",
    "    tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "    lsi_model = LsiModel(tfidf_corpus, id2word=dct, num_topics=15, power_iters=4)\n",
    "\n",
    "    index = MatrixSimilarity(lsi_model[tfidf_corpus])\n",
    "    my_model = MyModel(dictionary=dct,\n",
    "                       tfidf_model=tfidf_model,\n",
    "                       lsi_model=lsi_model,\n",
    "                       index=index)\n",
    "    pickle_save(my_model, MODEL_PATH)\n",
    "else:\n",
    "    my_model = pickle_load(MODEL_PATH)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### </Machine Learning Magic World 🧙‍♂️>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the query entity data as we did when creating the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query_bio = clean_text(get_artist_bio('Britney Spears'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <Machine Learning Magic World 🧙‍♂️>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `¯\\_(ツ)_/¯`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "similar_entities = my_model.index[vec_lsi]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### </Machine Learning Magic World 🧙‍♂️>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got all the doc numbers (see `mapping`) and how similar they are to the queried artist (0.0 to 1.0). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_to_similarity = dict(enumerate(similar_entities))\n",
    "pprint(doc_to_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's find the top 10 similar artists and bands."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_n_docs = sorted(doc_to_similarity, key=doc_to_similarity.get, reverse=True)[:10]\n",
    "\n",
    "result = []\n",
    "for doc_number in top_n_docs:\n",
    "    result.append({\n",
    "        'similarity': similar_entities[doc_number],\n",
    "        'artist_name': mapping[doc_number]['artist_name']\n",
    "    })\n",
    "    \n",
    "pprint(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 🤖 `I am a semi professional ML implementation AMA`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_similar_artists(artist_name):\n",
    "    # <Machine Learning Magic World 🧙‍♂️>\n",
    "    query_bio = clean_text(get_artist_bio(artist_name))\n",
    "    vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "    vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "    similar_entities = my_model.index[vec_lsi]\n",
    "    # </Machine Learning Magic World 🧙‍♂️>\n",
    "    doc_to_similarity = dict(enumerate(similar_entities))\n",
    "    top_n_docs = sorted(doc_to_similarity, key=doc_to_similarity.get, reverse=True)[:10]\n",
    "\n",
    "    result = []\n",
    "    for doc_number in top_n_docs:\n",
    "        result.append({\n",
    "            'similarity': similar_entities[doc_number],\n",
    "            'artist_name': mapping[doc_number]['artist_name']\n",
    "        })\n",
    "    sorted(result, key=lambda d: d['similarity'])\n",
    "    pprint(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_similar_artists(\"Eminem\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_similar_artists_by_prose(prose: str):\n",
    "    clean_prose = clean_text(prose)\n",
    "    # <Machine Learning Magic World 🧙‍♂️>\n",
    "    vec_bow = my_model.dictionary.doc2bow(clean_prose)\n",
    "    vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "    similar_entities = my_model.index[vec_lsi]\n",
    "    # </Machine Learning Magic World 🧙‍♂️>\n",
    "    doc_to_similarity = dict(enumerate(similar_entities))\n",
    "    top_n_docs = sorted(doc_to_similarity, key=doc_to_similarity.get, reverse=True)[:10]\n",
    "\n",
    "    result = []\n",
    "    for doc_number in top_n_docs:\n",
    "        result.append({\n",
    "            'similarity': similar_entities[doc_number],\n",
    "            'artist_name': mapping[doc_number]['artist_name']\n",
    "        })\n",
    "    sorted(result, key=lambda d: d['similarity'])\n",
    "    pprint(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prose = \"old school rap music from new york\"\n",
    "find_similar_artists_by_prose(prose)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Open Questions\n",
    "\n",
    "* How to update model without reading all data again?\n",
    "* Do too many artists from one genre sabotage the result?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problems That I faced\n",
    "\n",
    "* I did not save artists without bios. So everytime my data gathering broke, the rerunning script had to ask for all those artists again. \n",
    "* Artists that were duplicates but with uppercase/lowercase could not be added again to git index. Git does not seem to be the best blob storage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0868a19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4b30f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a67fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}