{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8609c1",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a36dc2",
   "metadata": {},
   "source": [
    "From someone who does not understand Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384da00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c7b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab23745",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffd4d2",
   "metadata": {},
   "source": [
    "#### Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230bdb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def pickle_save(obj, path):\n",
    "     with open(path, 'wb') as out:\n",
    "        pickle.dump(obj, out, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "\n",
    "def pickle_load(path):\n",
    "     with open(path, 'rb') as obj:\n",
    "        return pickle.load(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e38b5",
   "metadata": {},
   "source": [
    "#### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b3a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def _remove_html_tags(text):\n",
    "    cleaner = re.compile('<.*?>')\n",
    "    return re.sub(cleaner, '', text)\n",
    "\n",
    "\n",
    "def _remove_control_chars(text):\n",
    "    text = text.replace('\\n','')\n",
    "    text = text.replace('\\t','')\n",
    "    return text\n",
    "\n",
    "\n",
    "def _remove_stop_words(text):\n",
    "    stop_words = list()\n",
    "    stop_words.extend(stopwords.words('english'))\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = _remove_html_tags(text)\n",
    "    text = _remove_control_chars(text)\n",
    "    text = _remove_stop_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ce988",
   "metadata": {},
   "source": [
    "#### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86222872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_artist_names(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return [artist_name.strip() for artist_name in f.readlines()]\n",
    "\n",
    "\n",
    "def get_artist_bio(artist_name: str):\n",
    "    return clean_text(artist_name + \" data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728c254",
   "metadata": {},
   "source": [
    "# Buckle Up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e185ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_SCRATCH = True\n",
    "ARTIST_NAMES_PATH = 'data/artist_names.txt'\n",
    "MODEL_PATH = 'model.pickle'\n",
    "MAPPING_PATH = 'mapping.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1adcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\r\n",
      "├── \u001b[00mREADME.md\u001b[0m\r\n",
      "├── \u001b[01;34mdata\u001b[0m\r\n",
      "│   └── \u001b[00martist_names.txt\u001b[0m\r\n",
      "├── \u001b[00mmapping.pickle\u001b[0m\r\n",
      "├── \u001b[00mmodel.pickle\u001b[0m\r\n",
      "├── \u001b[00mrequirements.txt\u001b[0m\r\n",
      "└── \u001b[00mtopic-modelling-workshop.ipynb\u001b[0m\r\n",
      "\r\n",
      "1 directory, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -I venv  # With ! you can run bash commands in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a6395",
   "metadata": {},
   "source": [
    "## Data Cleansing and Preparation\n",
    "\n",
    "We create so called documents that consist of the artist name and their biography in tokenized format.\n",
    "\n",
    "The mapping looks something like this\n",
    "\n",
    "```\n",
    "{\n",
    "    1: {'artist_name': '50 Cent', 'bio': ['a', 'text', 'about', '50', 'Cent'},\n",
    "    2: {'artist_name': 'Eminem', 'bio': ['a', 'text', 'about', 'Eminem'},\n",
    "    3: {'artist_name': 'Metallica', 'bio': ['a', 'text', 'about', 'Metallica'},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a9e687",
   "metadata": {},
   "source": [
    "### Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8236010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anthony Danza', 'Anthony Hamilton', 'Anti Lilly', 'Antologie', 'Antonín Dvořák', 'Antwon', 'Antônio Carlos Jobim', 'Aperture Science Psychoacoustic Laboratories', 'Aphex Twin', 'Apocalyspe', 'Apollo', 'Apollo Brown', 'Apparat', 'April George', 'Aquarius Heaven', 'Aquilo', 'Arca', 'Arcade Fire', 'Arcangel', 'Archie Daggers & Tender Slider', 'Archie Lee', 'Architechs', 'Archy Marshall', 'Arctic Lake', 'Ardian Bujupi', 'Area', 'Aretha Franklin', 'Ari Lennox', 'Ari Rasilainen', 'Ariana Grande', 'Arianoknows', 'Arin Ray', 'Armageddon', 'Armando', 'Armin Rohde', 'Art Nap', 'Art Of Trance', 'Artem Kacher', 'Artful Dodger', 'Arthur Conley', 'Arthur Ross', 'Arthur Rubinstein', 'Arthur Russell', 'Artik & Asti', 'Asata', 'Ascent', 'Ash-Rock', 'Ashanti', 'Asher Roth', 'Ashley All Day', 'Assassin', 'Astero', 'Astrid', 'Astrid S', 'Astronaut Husband', 'Astronomyy', 'Astrud Gilberto', 'Athena Cage', 'Atlas Bound', 'Atmos T', 'Atom', 'Au/Ra', 'Audio Push', 'Audio88', 'August Alsina', 'August Rigo', 'Austen', 'Austin Cesear & Stefan J\\\\xF3s', 'Austin Lam', 'Autograf', 'Auður', 'Avalon Emerson', 'Avant', 'Avelina Boateng', 'Avelino', 'Avishai Cohen', 'Awon', 'Axel Boman', 'Axel Flovent', 'Aye Mitch', 'Ayelle', 'Ayo', 'Ayve', 'Azad', 'Azaleh', 'Azealia Banks', 'Azekel', 'Azet', 'Azizi Gibson', 'AzudemSK', 'B Rossi', 'B!G', 'B-JU', 'B-Ju & Ticklish', 'B-Legit', 'B-Real', 'B.B. King', 'B.G.', 'B.Slade', 'B.o.B', 'BASECAMP', 'BBC Scottish Symphony Orchestra', 'BBC Symphony Orchestra', 'BEEJ GORDY BROOKS', 'BHZ', 'BJ The Chicago Kid', 'BKA Iz', 'BLAGOIBLAGO', 'BLVK JVCK', 'BOLDLY JAMES', 'BONES', 'BOSCO', 'BOY', 'BRETT', 'BRIDGE', 'BROCKHAMPTON', 'BSMG', 'BSN Posse', 'Baauer', 'Baba Rico', 'Baba Stiltz', 'Babes Wodumo', 'Babik Reinhardt', 'Baby Doll Wall Noelle', 'Baby Ford', 'Baby Washington', 'Babyface', 'Babyford + EON', 'Backstreet Boys', 'Bad Bunny', 'Bad Company', 'Bad Suns', 'BadBadNotGood', 'Badesalz', 'Baegod', 'Bag Raiders', 'Bahar', 'Bailey', 'Bailey Abbott', 'Balearic', 'Baltimore Symphony Orchestra', 'Bambi Cruz', 'Bambus', 'Bandman Kevo', 'Banks', 'Barbara Moleko', 'Barbara Tucker', 'Barry Brown', 'Barry White', 'Bas', 'Basic Operations', 'Basics', 'Bassette', 'Bastille', 'Baths', 'Bato', 'Bausa', 'Bcee', 'Be Godfrey', 'Beach Fossils', 'Beach House', 'Beacon', 'Beady Belle', 'Beanie Sigel', 'Bearcubs', 'Beat De Boul', 'Beatsteaks', 'Beaumont', 'Becca Adams', 'Beck', 'Beckett', \"Bee's Knees\", 'Beenie Man', 'Beginner', 'Beirut', 'Bela Nemeth', 'Bell Biv DeVoe', 'Belly', 'Ben Duffy', 'Ben Harper', 'Ben Tamale', 'Ben Webster', 'Bender & Schillinger', 'Benjamin Blümchen', 'Benjamin Brunn', 'Benjamin Clementine', 'Benjamin Godard', 'Benjamin Wallfisch', 'Benno Kusche', 'Benny Benassi', 'Benny Blanco', 'Benny Mails', 'Benny Treskow', 'Benoit & Sergio', 'Berhana', 'Berlin', 'Berliner Philharmoniker', 'Bernard Herrmann', 'Bernard Labadie', 'Berner', 'Bertrand Noel', 'Beshken', 'Betty Wright', 'Beverlay', 'Beyoncé', 'Bezel', 'Bibi Blocksberg', 'Bibio', 'Bicep', 'Biffguyz', 'Big Boi', 'Big Bud', 'Big Gipp', 'Big K.R.I.T.', 'Big L', 'Big Lenbo', 'Big Mack', 'Big Moe', 'Big Narstie', 'Big Noyd', 'Big Pun', 'Big Russian Boss', 'Big Sean', 'Big Shaq', 'Big Syke', 'Big T', 'Big TC', 'Big Tymers', 'Bilal', 'Bilderbuch', 'Bill Pinckney', 'Bill Withers', 'Billie Black', 'Billie Eilish', 'Billie Holiday', 'Billie Marten', 'Billy Cobham', 'Billy Idol', 'Billy Joel', 'Billy Lemos', 'Billy Milligan', 'Billy Paul', 'Bimbo Beutlin', 'Binary One', 'Bing Crosby', 'Bino Rideaux', 'Bintia', 'Bipolar Sunshine', 'Birdman', 'Birdy Nam Nam', 'Bishat', 'Bishop Briggs', 'Bishop Nehru', 'Bizarre', 'Bizzy Bone', 'Bizzy Crook', 'Bjarki', 'Björk', 'Björn J:son Lindh Staffan Scheja', 'Blac Youngsta', 'Black Atlass', 'Black Boe', 'Black Coffee', 'Black Milk', 'Black Shakespeare', 'Black Spade', 'Black The Ripper', 'Black Thought of The Roots', 'Blackbear', 'Blackdown', 'Blade', 'Bladee', 'Blanco', 'Blanco White', 'Blank Banshee', 'Blasko', 'Blawan', 'Blaze', 'Blazo', 'Blizz Wright', 'Bloc Party', 'BlocBoy JB', 'Blockbuster Orchestra', 'Blondage', 'Blonde', 'Blood Orange', 'Bloody Jay', 'Blu', 'Blu & Exile', 'Blu Samu', 'Blue Foundation', 'Blue Hawaii', 'Blue Lab Beats', 'Blue Room Mafia', 'Bluestaeb', 'BluntOne', 'Bo & Ferris Mc', 'Bo Kirkland', 'Bo Saris', 'Boards of Canada', 'Bob Moses', 'Bob Sinclar', 'Bobbito Garcia', 'Bobby \"Blue\" Bland', 'Bobby Brackins', 'Bobby Brown', 'Bobby Caldwell', 'Bobby V.', 'Bobby Womack', 'Bodega Bamz', 'Bohan Phoenix', 'Bohren & Der Club Of Gore', 'Bok Bok', 'Bon Iver', 'Bondax', 'Bone Thugs-N-Harmony', 'Bonecold', 'Bonez MC', 'Bonkaz', 'Bonobo', 'Bonzai', 'Booba', 'Boogie', 'Booka Shade', \"Booker T. & the M.G.'s\", 'Boom Clap Bachelors', 'Boosie Badazz', 'Boot Camp Clik', 'Bootsy Collins', 'Bora York', 'Borgore', 'Boris Brejcha', 'Boris Dlugosch']\n"
     ]
    }
   ],
   "source": [
    "artist_names = load_artist_names(ARTIST_NAMES_PATH)\n",
    "print(artist_names[234:567])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77137dae",
   "metadata": {},
   "source": [
    "### Load Artists Bios and Create Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "147da698",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FROM_SCRATCH:\n",
    "    mapping = {}\n",
    "    for doc_number, artist_name in enumerate(artist_names):\n",
    "        bio = get_artist_bio(artist_name)\n",
    "        if bio:\n",
    "            mapping[doc_number] = {\n",
    "                'artist_name': artist_name,\n",
    "                'bio': bio,\n",
    "            }\n",
    "    pickle_save(mapping, MAPPING_PATH)\n",
    "else:\n",
    "    mapping = pickle_load(MAPPING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f150364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'artist_name': '50 Cent', 'bio': ['50', 'Cent', 'data']}, 1: {'artist_name': 'Eminem', 'bio': ['Eminem', 'data']}, 2: {'artist_name': 'Metallica', 'bio': ['Metallica', 'data']}, 3: {'artist_name': 'Obie Trice', 'bio': ['Obie', 'Trice', 'data']}}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd849bf",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eac257",
   "metadata": {},
   "source": [
    "#### <Machine Learning Magic World 🧙‍♂️>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `¯\\_(ツ)_/¯`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1e1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyModel:\n",
    "    dictionary: Dictionary\n",
    "    tfidf_model: TfidfModel\n",
    "    lsi_model: LsiModel\n",
    "    index: MatrixSimilarity\n",
    "    \n",
    "\n",
    "if FROM_SCRATCH:\n",
    "    dataset = [mapping[i]['bio'] for i in mapping]\n",
    "    \n",
    "    dct = Dictionary(dataset)\n",
    "\n",
    "    corpus = [dct.doc2bow(line) for line in dataset]\n",
    "    tfidf_model = TfidfModel(corpus)\n",
    "    tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "    lsi_model = LsiModel(tfidf_corpus, id2word=dct, num_topics=50, power_iters=4)\n",
    "\n",
    "    index = MatrixSimilarity(lsi_model[tfidf_corpus])\n",
    "    my_model = MyModel(dictionary=dct,\n",
    "                       tfidf_model=tfidf_model,\n",
    "                       lsi_model=lsi_model,\n",
    "                       index=index)\n",
    "    pickle_save(my_model, MODEL_PATH)\n",
    "else:\n",
    "    my_model = pickle_load(MODEL_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd508c3",
   "metadata": {},
   "source": [
    "#### </Machine Learning Magic World 🧙‍♂️>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dc9a3",
   "metadata": {},
   "source": [
    "## Query the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2cbaf",
   "metadata": {},
   "source": [
    "Create the query entity data as we did when creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc349a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bio = get_artist_bio('Obie Trice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7fd06",
   "metadata": {},
   "source": [
    "#### <Machine Learning Magic World 🧙‍♂️>\n",
    "\n",
    "The following code is not there to be understood. Thanks. `¯\\_(ツ)_/¯`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2786a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "similar_entities = my_model.index[vec_lsi]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fbd5e",
   "metadata": {},
   "source": [
    "#### </Machine Learning Magic World 🧙‍♂️>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3241de0",
   "metadata": {},
   "source": [
    "## The Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e864b",
   "metadata": {},
   "source": [
    "We got all the doc numbers (see `mapping`) and how similar they are to the queried artist (0.0 to 1.0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a26bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.99999994}\n"
     ]
    }
   ],
   "source": [
    "doc_to_similarity = dict(enumerate(similar_entities))\n",
    "\n",
    "print(doc_to_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c24c4",
   "metadata": {},
   "source": [
    "Now let's find the top 10 similar artists and bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863b2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'similarity': 0.99999994, 'artist_name': 'Obie Trice'}, {'similarity': 0.0, 'artist_name': '50 Cent'}, {'similarity': 0.0, 'artist_name': 'Eminem'}, {'similarity': 0.0, 'artist_name': 'Metallica'}]\n"
     ]
    }
   ],
   "source": [
    "top_n_docs = sorted(doc_to_similarity, key=doc_to_similarity.get, reverse=True)[:10]\n",
    "\n",
    "result = []\n",
    "for doc_number in top_n_docs:\n",
    "    result.append({\n",
    "        'similarity': similar_entities[doc_number],\n",
    "        'artist_name': mapping[doc_number]['artist_name']\n",
    "    })\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760808b2",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f777aa33",
   "metadata": {},
   "source": [
    "### 🤖 `I am a semi professional ML implementation AMA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e3f08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def find_similar_artists(artist_name):\n",
    "    # <Machine Learning Magic World 🧙‍♂️>\n",
    "    query_bio = get_artist_bio(artist_name)\n",
    "    vec_bow = my_model.dictionary.doc2bow(query_bio)\n",
    "    vec_lsi = my_model.lsi_model[my_model.tfidf_model[vec_bow]]\n",
    "    similar_entities = my_model.index[vec_lsi]\n",
    "    # </Machine Learning Magic World 🧙‍♂️>\n",
    "    doc_to_similarity = dict(enumerate(similar_entities))\n",
    "    top_n_docs = sorted(doc_to_similarity, key=doc_to_similarity.get, reverse=True)[:10]\n",
    "\n",
    "    result = []\n",
    "    for doc_number in top_n_docs:\n",
    "        result.append({\n",
    "            'similarity': similar_entities[doc_number],\n",
    "            'artist_name': mapping[doc_number]['artist_name']\n",
    "        })\n",
    "    sorted(result, key=lambda d: d['similarity'])\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93844d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'artist_name': 'Obie Trice', 'similarity': 0.99999994},\n",
      " {'artist_name': '50 Cent', 'similarity': 0.0},\n",
      " {'artist_name': 'Eminem', 'similarity': 0.0},\n",
      " {'artist_name': 'Metallica', 'similarity': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "find_similar_artists(\"Obie Trice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e4079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
